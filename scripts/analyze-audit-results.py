#!/usr/bin/env python3
"""
ì •ë¶€ì§€ì›ê¸ˆ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ Audit ê²°ê³¼ ìë™ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python scripts/analyze-audit-results.py

í•„ìˆ˜ íŒŒì¼:
    - scripts/audit-1000-final.json (í•„ìˆ˜)
    - scripts/audit-1000-results.json (ì„ íƒ, v3 ë¹„êµìš©)

ì¶œë ¥:
    - ì½˜ì†”ì— ë¶„ì„ ê²°ê³¼ ì¶œë ¥
    - MATCHING_QUALITY_REPORT.md ìë™ ì—…ë°ì´íŠ¸ (í–¥í›„ êµ¬í˜„)
"""

import json
import statistics
from collections import defaultdict, Counter
from typing import Dict, List, Any, Optional
from pathlib import Path


def load_audit_data(filepath: str) -> List[Dict]:
    """Audit ê²°ê³¼ íŒŒì¼ ë¡œë“œ"""
    path = Path(filepath)
    if not path.exists():
        raise FileNotFoundError(f"íŒŒì¼ ì—†ìŒ: {filepath}")

    with open(path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    print(f"âœ“ ë¡œë“œ ì™„ë£Œ: {filepath} ({len(data)} cases)")
    return data


def calculate_basic_stats(values: List[float]) -> Dict[str, float]:
    """ê¸°ë³¸ í†µê³„ëŸ‰ ê³„ì‚°"""
    if not values or len(values) == 0:
        return {}

    sorted_values = sorted(values)
    n = len(values)

    stats = {
        'count': n,
        'mean': statistics.mean(values),
        'median': statistics.median(values),
        'min': min(values),
        'max': max(values),
    }

    if n > 1:
        stats['stdev'] = statistics.stdev(values)
        stats['variance'] = statistics.variance(values)

    if n >= 4:
        quantiles = statistics.quantiles(values, n=4)
        stats['q25'] = quantiles[0]
        stats['q75'] = quantiles[2]
        stats['iqr'] = quantiles[2] - quantiles[0]

    return stats


def analyze_score_distribution(data: List[Dict]) -> Dict[str, Any]:
    """ìŠ¤ì½”ì–´ ë¶„í¬ ë¶„ì„"""
    print("\n" + "="*60)
    print("1. ìŠ¤ì½”ì–´ ë¶„í¬ ë¶„ì„")
    print("="*60)

    scores = [case['score'] for case in data if 'score' in case]
    if not scores:
        print("âš ï¸  ìŠ¤ì½”ì–´ ë°ì´í„° ì—†ìŒ")
        return {}

    stats = calculate_basic_stats(scores)

    print(f"\nğŸ“Š ê¸°ë³¸ í†µê³„ëŸ‰:")
    print(f"  - ì¼€ì´ìŠ¤ ìˆ˜: {stats['count']}")
    print(f"  - í‰ê· : {stats['mean']:.4f}")
    print(f"  - ì¤‘ì•™ê°’: {stats['median']:.4f}")
    print(f"  - í‘œì¤€í¸ì°¨: {stats.get('stdev', 0):.4f}")
    print(f"  - ìµœì†Œê°’: {stats['min']:.4f}")
    print(f"  - ìµœëŒ€ê°’: {stats['max']:.4f}")

    if 'q25' in stats:
        print(f"  - Q1 (25%): {stats['q25']:.4f}")
        print(f"  - Q3 (75%): {stats['q75']:.4f}")
        print(f"  - IQR: {stats['iqr']:.4f}")

    # ì ìˆ˜ êµ¬ê°„ ë¶„í¬
    bins = [0, 0.15, 0.35, 0.55, 1.0]
    labels = ['< 0.15 (Hidden)', '0.15-0.35 (Exploratory)',
              '0.35-0.55 (Recommended)', 'â‰¥ 0.55 (Tailored)']

    distribution = Counter()
    for score in scores:
        for i, threshold in enumerate(bins[1:]):
            if score < threshold:
                distribution[labels[i]] += 1
                break

    print(f"\nğŸ“ˆ ì ìˆ˜ êµ¬ê°„ ë¶„í¬:")
    for label in labels:
        count = distribution[label]
        pct = (count / len(scores)) * 100
        print(f"  - {label}: {count}ê±´ ({pct:.1f}%)")

    return {
        'stats': stats,
        'distribution': dict(distribution)
    }


def analyze_tier_distribution(data: List[Dict]) -> Dict[str, Any]:
    """Tier ë¶„í¬ ë¶„ì„"""
    print("\n" + "="*60)
    print("2. Tier ë¶„í¬ ë¶„ì„")
    print("="*60)

    tiers = [case['tier'] for case in data if 'tier' in case]
    if not tiers:
        print("âš ï¸  Tier ë°ì´í„° ì—†ìŒ")
        return {}

    tier_counts = Counter(tiers)
    total = len(tiers)

    print(f"\nğŸ¯ Tier ë¶„í¬:")
    for tier in ['tailored', 'recommended', 'exploratory']:
        count = tier_counts.get(tier, 0)
        pct = (count / total) * 100
        print(f"  - {tier.capitalize()}: {count}ê±´ ({pct:.1f}%)")

    return {
        'counts': dict(tier_counts),
        'total': total,
        'proportions': {k: v/total for k, v in tier_counts.items()}
    }


def analyze_dimension_contribution(data: List[Dict]) -> Dict[str, Any]:
    """ì°¨ì›ë³„ ê¸°ì—¬ë„ ë¶„ì„"""
    print("\n" + "="*60)
    print("3. ì°¨ì›ë³„ ê¸°ì—¬ë„ ë¶„ì„")
    print("="*60)

    # ê°œì¸/ì‚¬ì—…ì êµ¬ë¶„
    personal_dimensions = ['region', 'age', 'householdType', 'incomeLevel', 'employmentStatus']
    business_dimensions = ['region', 'businessAge', 'businessType', 'employee', 'founderAge', 'revenue']

    dimension_scores: Dict[str, List[float]] = defaultdict(list)
    dimension_weights: Dict[str, float] = {}

    for case in data:
        if 'breakdown' not in case:
            continue

        breakdown = case['breakdown']
        for dim, score in breakdown.items():
            if isinstance(score, (int, float)):
                dimension_scores[dim].append(score)

    print(f"\nğŸ“Š ì°¨ì›ë³„ í‰ê·  ì ìˆ˜:")
    sorted_dims = sorted(dimension_scores.items(),
                        key=lambda x: statistics.mean(x[1]) if x[1] else 0,
                        reverse=True)

    for dim, scores in sorted_dims:
        if scores:
            avg = statistics.mean(scores)
            count = len(scores)
            print(f"  - {dim}: {avg:.4f} (n={count})")

    return {
        'dimension_scores': {k: calculate_basic_stats(v) for k, v in dimension_scores.items()}
    }


def analyze_knockout_effect(data: List[Dict]) -> Dict[str, Any]:
    """Knockout íš¨ê³¼ ë¶„ì„"""
    print("\n" + "="*60)
    print("4. Knockout í•„í„°ë§ íš¨ê³¼")
    print("="*60)

    total_analyzed = 0
    total_knocked_out = 0
    total_filtered_by_type = 0
    total_matched = 0

    for case in data:
        if 'totalAnalyzed' in case:
            total_analyzed += case['totalAnalyzed']
        if 'knockedOut' in case:
            total_knocked_out += case['knockedOut']
        if 'filteredByServiceType' in case:
            total_filtered_by_type += case['filteredByServiceType']
        if 'totalCount' in case:
            total_matched += case['totalCount']

    n_cases = len(data)
    if n_cases > 0:
        avg_analyzed = total_analyzed / n_cases
        avg_knocked_out = total_knocked_out / n_cases
        avg_filtered = total_filtered_by_type / n_cases
        avg_matched = total_matched / n_cases

        print(f"\nğŸ” í•„í„°ë§ í†µê³„ (í‰ê· ):")
        print(f"  - ë¶„ì„ ëŒ€ìƒ: {avg_analyzed:.1f}ê°œ")
        print(f"  - Service Type í•„í„°: {avg_filtered:.1f}ê°œ ({avg_filtered/avg_analyzed*100:.1f}%)")
        print(f"  - Knockout ì œê±°: {avg_knocked_out:.1f}ê°œ ({avg_knocked_out/avg_analyzed*100:.1f}%)")
        print(f"  - ìµœì¢… ë§¤ì¹­: {avg_matched:.1f}ê°œ ({avg_matched/avg_analyzed*100:.1f}%)")

        return {
            'avg_analyzed': avg_analyzed,
            'avg_knocked_out': avg_knocked_out,
            'avg_filtered': avg_filtered,
            'avg_matched': avg_matched,
            'knockout_rate': avg_knocked_out / avg_analyzed if avg_analyzed > 0 else 0
        }

    return {}


def compare_versions(v3_data: List[Dict], v4_data: List[Dict]) -> Dict[str, Any]:
    """v3 vs v4 ë¹„êµ ë¶„ì„"""
    print("\n" + "="*60)
    print("5. v3 vs v4 ë¹„êµ ë¶„ì„")
    print("="*60)

    v3_scores = [case['score'] for case in v3_data if 'score' in case]
    v4_scores = [case['score'] for case in v4_data if 'score' in case]

    if not v3_scores or not v4_scores:
        print("âš ï¸  ë¹„êµ ë°ì´í„° ë¶ˆì¶©ë¶„")
        return {}

    if len(v3_scores) != len(v4_scores):
        print(f"âš ï¸  ì¼€ì´ìŠ¤ ìˆ˜ ë¶ˆì¼ì¹˜: v3={len(v3_scores)}, v4={len(v4_scores)}")
        min_len = min(len(v3_scores), len(v4_scores))
        v3_scores = v3_scores[:min_len]
        v4_scores = v4_scores[:min_len]

    # ìŒì²´ ì°¨ì´
    diffs = [v4 - v3 for v3, v4 in zip(v3_scores, v4_scores)]

    v3_stats = calculate_basic_stats(v3_scores)
    v4_stats = calculate_basic_stats(v4_scores)
    diff_stats = calculate_basic_stats(diffs)

    print(f"\nğŸ“Š í‰ê·  ì ìˆ˜ ë¹„êµ:")
    print(f"  - v3 í‰ê· : {v3_stats['mean']:.4f}")
    print(f"  - v4 í‰ê· : {v4_stats['mean']:.4f}")
    print(f"  - ì°¨ì´ (Î”): {diff_stats['mean']:.4f}")
    print(f"  - ê°œì„ ìœ¨: {(diff_stats['mean']/v3_stats['mean']*100):.1f}%")

    print(f"\nğŸ“Š ì¤‘ì•™ê°’ ë¹„êµ:")
    print(f"  - v3 ì¤‘ì•™ê°’: {v3_stats['median']:.4f}")
    print(f"  - v4 ì¤‘ì•™ê°’: {v4_stats['median']:.4f}")
    print(f"  - ì°¨ì´: {v4_stats['median'] - v3_stats['median']:.4f}")

    # Cohen's d (pooled standard deviation)
    if 'stdev' in v3_stats and 'stdev' in v4_stats:
        n1, n2 = len(v3_scores), len(v4_scores)
        pooled_std = ((n1-1)*v3_stats['stdev']**2 + (n2-1)*v4_stats['stdev']**2) / (n1+n2-2)
        pooled_std = pooled_std ** 0.5

        cohens_d = (v4_stats['mean'] - v3_stats['mean']) / pooled_std

        effect_size = 'Negligible'
        if abs(cohens_d) >= 0.8:
            effect_size = 'Large'
        elif abs(cohens_d) >= 0.5:
            effect_size = 'Medium'
        elif abs(cohens_d) >= 0.2:
            effect_size = 'Small'

        print(f"\nğŸ“ˆ Effect Size (Cohen's d):")
        print(f"  - d = {cohens_d:.3f} ({effect_size})")

    # Tier ì´ë™ ë¶„ì„
    v3_tiers = [case.get('tier') for case in v3_data]
    v4_tiers = [case.get('tier') for case in v4_data]

    if all(v3_tiers) and all(v4_tiers):
        upgrades = sum(1 for v3, v4 in zip(v3_tiers, v4_tiers)
                      if v3 == 'recommended' and v4 == 'tailored')
        downgrades = sum(1 for v3, v4 in zip(v3_tiers, v4_tiers)
                        if v3 == 'tailored' and v4 == 'recommended')

        print(f"\nğŸ”„ Tier ì´ë™:")
        print(f"  - Upgrade (recommendedâ†’tailored): {upgrades}ê±´")
        print(f"  - Downgrade (tailoredâ†’recommended): {downgrades}ê±´")
        print(f"  - Net Change: {upgrades - downgrades:+d}ê±´")

    return {
        'v3_stats': v3_stats,
        'v4_stats': v4_stats,
        'diff_stats': diff_stats,
        'cohens_d': cohens_d if 'cohens_d' in locals() else None
    }


def main():
    """ë©”ì¸ ë¶„ì„ ì‹¤í–‰"""
    print("="*60)
    print("ì •ë¶€ì§€ì›ê¸ˆ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ Audit ê²°ê³¼ ë¶„ì„")
    print("="*60)

    # v4 ë°ì´í„° ë¡œë“œ (í•„ìˆ˜)
    try:
        v4_data = load_audit_data('scripts/audit-1000-final.json')
    except FileNotFoundError as e:
        print(f"\nâŒ {e}")
        print("\nâ³ audit-1000-final.json íŒŒì¼ì´ ìƒì„±ë˜ë©´ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    # v3 ë°ì´í„° ë¡œë“œ (ì„ íƒ)
    v3_data = None
    try:
        v3_data = load_audit_data('scripts/audit-1000-results.json')
    except FileNotFoundError:
        print("â„¹ï¸  v3 baseline íŒŒì¼ ì—†ìŒ (ë¹„êµ ë¶„ì„ ê±´ë„ˆëœ€)")

    # ë¶„ì„ ì‹¤í–‰
    score_analysis = analyze_score_distribution(v4_data)
    tier_analysis = analyze_tier_distribution(v4_data)
    dimension_analysis = analyze_dimension_contribution(v4_data)
    knockout_analysis = analyze_knockout_effect(v4_data)

    # v3 ë¹„êµ (ê°€ëŠ¥í•œ ê²½ìš°)
    if v3_data:
        comparison = compare_versions(v3_data, v4_data)

    # ìš”ì•½
    print("\n" + "="*60)
    print("ğŸ“‹ ë¶„ì„ ìš”ì•½")
    print("="*60)

    if score_analysis and 'stats' in score_analysis:
        stats = score_analysis['stats']
        print(f"\nâœ“ í‰ê·  ë§¤ì¹­ ìŠ¤ì½”ì–´: {stats['mean']:.4f}")
        print(f"âœ“ ì¤‘ì•™ê°’: {stats['median']:.4f}")

    if tier_analysis and 'proportions' in tier_analysis:
        props = tier_analysis['proportions']
        print(f"âœ“ Tailored ë¹„ìœ¨: {props.get('tailored', 0)*100:.1f}%")
        print(f"âœ“ Recommended ë¹„ìœ¨: {props.get('recommended', 0)*100:.1f}%")

    if knockout_analysis and 'knockout_rate' in knockout_analysis:
        print(f"âœ“ í‰ê·  Knockout ë¹„ìœ¨: {knockout_analysis['knockout_rate']*100:.1f}%")

    print("\n" + "="*60)
    print("âœ… ë¶„ì„ ì™„ë£Œ")
    print("="*60)


if __name__ == '__main__':
    main()
